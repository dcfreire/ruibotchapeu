{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/spmallick/learnopencv/blob/5d9e05bce247e475488a40cfec0de11c006db532/Homography/utils.py\n",
    "\n",
    "def mouse_handler(event, x, y, flags, data) :\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN :\n",
    "        cv2.circle(data['im'], (x,y),3, (0,0,255), 5, 16)\n",
    "        cv2.imshow(\"Image\", data['im']);\n",
    "        if len(data['points']) < 4 :\n",
    "            data['points'].append([x,y])\n",
    "        \n",
    "def get_four_points(im):\n",
    "    \n",
    "    # Set up data to send to mouse handler\n",
    "    data = {}\n",
    "    data['im'] = im.copy()\n",
    "    data['points'] = []\n",
    "    \n",
    "    #Set the callback function for any mouse event\n",
    "    cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Image\",im)\n",
    "    cv2.setMouseCallback(\"Image\", mouse_handler, data)\n",
    "    while cv2.waitKey(0) != ord('q'):\n",
    "        pass\n",
    "    cv2.destroyAllWindows()\n",
    "    # Convert array to np.array\n",
    "    points = np.vstack(data['points']).astype(float)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/jrosebr1/imutils/blob/master/imutils/convenience.py\n",
    "\"\"\"\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "TESTE DO OTSU PRA CROP -> HOMOGRAPHY\n",
    "\n",
    "https://stackoverflow.com/questions/60780831/python-how-to-cut-out-an-area-with-specific-color-from-image-opencv-numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "mega clean == blur no output de canny\n",
    "mesa branca == blur em src -> otsu no blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "src = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "dst = cv2.Canny(src, 50, 100, None, 3)\n",
    "blur = cv2.GaussianBlur(src,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "lines = cv2.HoughLinesP(th3, 1, np.pi / 180, 150, None, 0, 0)\n",
    "for line in lines:\n",
    "\t    x1, y1, x2, y2 = line[0]\n",
    "\t    cv2.line(src, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "cv2.namedWindow('Result Image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Result Image\", th3)\n",
    "while cv2.waitKey(0) != ord('q'):\n",
    "        pass\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eof\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(fname)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"eof\")\n",
    "        break\n",
    "\n",
    "    src = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    blur = cv2.GaussianBlur(src,(5,5),0)\n",
    "\n",
    "\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    cnts, _ = cv2.findContours(th3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(cnts, key = cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "    cv2.drawContours(frame, c, -1, (255, 0, 0), 3)\n",
    "\n",
    "    cv2.namedWindow('Result Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Result Image\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "#outv.release(\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "\n",
    "shot = []\n",
    "\n",
    "# TODO: Automatic table corner detection\n",
    "ret, frame = cap.read()\n",
    "#cv2.imshow(\"Image\", frame)\n",
    "pts_src = get_four_points(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (500, 1000, 3)\n",
    "pts_dst = np.array(\n",
    "               [\n",
    "                [0,0],\n",
    "                [size[0] - 1, 0],\n",
    "                [size[0] - 1, size[1] -1],\n",
    "                [0, size[1] - 1 ]\n",
    "                ], dtype=float\n",
    "               )\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"eof\")\n",
    "        break\n",
    "\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "    im_dst = cv2.warpPerspective(frame, h, size[:2])\n",
    "    cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Image\", im_dst)\n",
    "    shot.append(im_dst)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test.jpg\", shot[0])\n",
    "\n",
    "for frame in shot:\n",
    "    # Smooth\n",
    "    frame_blur = cv2.GaussianBlur(frame, (0,0), 2)\n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Snooker green color range for judd.webm\n",
    "    lowerb = np.array([52, 150, 50])\n",
    "    upperb = np.array([60, 255, 220])\n",
    "    mask = cv2.inRange(frame_hsv, lowerb, upperb)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask_closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) # Cleans inner points\n",
    "    \n",
    "    # Applies the mask to the original frame\n",
    "    _,mask_inv = cv2.threshold(mask_closing,5,255,cv2.THRESH_BINARY_INV)\n",
    "    masked_img = cv2.bitwise_and(frame,frame, mask=mask_inv)\n",
    "\n",
    "    ctrs, hierarchy = cv2.findContours(mask_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ctrs = [ctr for ctr in ctrs\n",
    "                        if 300 < cv2.contourArea(ctr) < 1000\n",
    "                        #and cv2.minAreaRect(ctr)[1][0]*0.28 < cv2.minAreaRect(ctr)[1][1]\n",
    "                        #and cv2.minAreaRect(ctr)[1][1]*0.28 < cv2.minAreaRect(ctr)[1][0]\n",
    "            ]\n",
    "    frame = frame.copy()\n",
    "    #draw_rectangles(ctrs, frame)\n",
    "    cv2.drawContours(frame, ctrs, -1, (255, 0, 0), 3)\n",
    "    cv2.namedWindow('FRAME', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"FRAME\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = cv2.selectROI(\"tracker\", shot[0])\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /build/opencv/src/opencv-4.5.3/modules/video/src/tracking/detail/tracking_feature.cpp:128: error: (-215:Assertion failed) !patchSize.empty() in function 'generateRandomFeature'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3af323558471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerMIL_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /build/opencv/src/opencv-4.5.3/modules/video/src/tracking/detail/tracking_feature.cpp:128: error: (-215:Assertion failed) !patchSize.empty() in function 'generateRandomFeature'\n"
     ]
    }
   ],
   "source": [
    "tracker = cv2.TrackerMIL_create()\n",
    "tracker.init(shot[0], roi)\n",
    "for frame in shot:\n",
    "    frame = frame.copy()\n",
    "    _, roi = tracker.update(frame)\n",
    "    cv2.rectangle(frame, roi, (255, 0, 0), 2, 1)\n",
    "    cv2.imshow(\"tracker\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = cv2.TrackerCSRT(shot[0], roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'MultiTracker'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-642c9112b640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrackers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'MultiTracker'"
     ]
    }
   ],
   "source": [
    "trackers = cv2.legacy.MultiTracker_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getContours(img):\n",
    "    cnts, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "    approx = cv2.approxPolyDP(c, 0.03 * cv2.arcLength(c, True), True)\n",
    "    return approx, c\n",
    "\n",
    "def order_points(points):\n",
    "    center = np.mean(points)\n",
    "    shifted = points - center\n",
    "    theta = np.arctan2(shifted[:, 0], shifted[:, 1])\n",
    "    ind = np.argsort(theta)\n",
    "    return points[ind]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 540  295]\n [ 358  892]\n [1559  896]\n [1365  290]]\n[[  0.   0.]\n [  0. 999.]\n [499. 999.]\n [499.   0.]]\n"
     ]
    }
   ],
   "source": [
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 1)\n",
    "canny = cv2.Canny(blur, 50, 150)\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "diler = cv2.morphologyEx(canny, cv2.MORPH_CLOSE, kernel)\n",
    "cv2.imshow(\"TESTE\", diler)\n",
    "if cv2.waitKey(0) == ord('q'):\n",
    "    cv2.destroyAllWindows()\n",
    "pts_src, c = getContours(diler)\n",
    "\n",
    "cv2.drawContours(frame, c, -1, (255, 0, 0), 3)\n",
    "cv2.imshow(\"TESTE\", frame)\n",
    "while True:\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "size = (500, 1000, 3)\n",
    "\n",
    "pts_dst = np.array(\n",
    "               [\n",
    "                [0,0],\n",
    "                [size[0] - 1, 0],\n",
    "                [size[0] - 1, size[1] -1],\n",
    "                [0, size[1] - 1 ]\n",
    "                ], dtype=float\n",
    "               )\n",
    "pts_src = order_points(pts_src[:, 0])\n",
    "pts_dst = order_points(pts_dst)\n",
    "print(pts_src)\n",
    "print(pts_dst)\n",
    "h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "im_dst = cv2.warpPerspective(frame, h, size[:2])\n",
    "cv2.imshow(\"IMAGE\", im_dst)\n",
    "while True:\n",
    "    if cv2.waitKey(0) == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[[ 540,  295]],\n",
       "\n",
       "       [[ 358,  892]],\n",
       "\n",
       "       [[1559,  896]],\n",
       "\n",
       "       [[1365,  290]]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pts_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eof\n"
     ]
    }
   ],
   "source": [
    "from detector_juba.table_contours import get_cloth_mask, get_ball_contours, get_homography, get_cloth_range\n",
    "import cv2\n",
    "import numpy as np\n",
    "video = []\n",
    "\n",
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "h = get_homography(frame, (600, 1000))\n",
    "im_dst = cv2.warpPerspective(frame, h, (600, 1000))\n",
    "\n",
    "hsv = cv2.cvtColor(im_dst, cv2.COLOR_BGR2HSV)\n",
    "hue, s, v = cv2.split(hsv)\n",
    "lower, upper = get_cloth_range(hue, s, v)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"eof\")\n",
    "        break\n",
    "\n",
    "\n",
    "    im_dst = cv2.warpPerspective(frame, h, (600, 1000))\n",
    "    warped = im_dst.copy()\n",
    "    mask = get_cloth_mask(im_dst, lower, upper)\n",
    "\n",
    "    ctrs = get_ball_contours(mask)\n",
    "\n",
    "    for c in ctrs:\n",
    "        x, y, w, z = cv2.boundingRect(c)\n",
    "        x -= 10\n",
    "        y -= 10\n",
    "        w += 15\n",
    "        z += 15\n",
    "        cv2.rectangle(im_dst,(x,y),(x+w,y+z),(0,0,255),2)\n",
    "\n",
    "    masked_img = cv2.bitwise_and(im_dst, im_dst, mask=mask)\n",
    "\n",
    "    cv2.drawContours(im_dst, ctrs, -1, (255, 0, 0), 3)\n",
    "\n",
    "    im_h = cv2.hconcat([warped, cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), masked_img, im_dst])\n",
    "    video.append(im_h)\n",
    "    cv2.imshow(\"Image\", im_h)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveVideo(frames, size=(640, 480)):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'FMP4')\n",
    "    out = cv2.VideoWriter('output.mp4', fourcc, 30, (2400, 1000))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "saveVideo(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}