{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6-final"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python39664bit149e8382a9df46e38b7b416944f0faa3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/spmallick/learnopencv/blob/5d9e05bce247e475488a40cfec0de11c006db532/Homography/utils.py\n",
    "\n",
    "def mouse_handler(event, x, y, flags, data) :\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN :\n",
    "        cv2.circle(data['im'], (x,y),3, (0,0,255), 5, 16)\n",
    "        cv2.imshow(\"Image\", data['im']);\n",
    "        if len(data['points']) < 4 :\n",
    "            data['points'].append([x,y])\n",
    "        \n",
    "def get_four_points(im):\n",
    "    \n",
    "    # Set up data to send to mouse handler\n",
    "    data = {}\n",
    "    data['im'] = im.copy()\n",
    "    data['points'] = []\n",
    "    \n",
    "    #Set the callback function for any mouse event\n",
    "    cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Image\",im)\n",
    "    cv2.setMouseCallback(\"Image\", mouse_handler, data)\n",
    "    while cv2.waitKey(0) != ord('q'):\n",
    "        pass\n",
    "    cv2.destroyAllWindows()\n",
    "    # Convert array to np.array\n",
    "    points = np.vstack(data['points']).astype(float)\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://github.com/jrosebr1/imutils/blob/master/imutils/convenience.py\n",
    "\"\"\"\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts"
   ]
  },
  {
   "source": [
    "TESTE DO OTSU PRA CROP -> HOMOGRAPHY\n",
    "\n",
    "https://stackoverflow.com/questions/60780831/python-how-to-cut-out-an-area-with-specific-color-from-image-opencv-numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "mega clean == blur no output de canny\n",
    "mesa branca == blur em src -> otsu no blur"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "src = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "dst = cv2.Canny(src, 50, 100, None, 3)\n",
    "blur = cv2.GaussianBlur(src,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "lines = cv2.HoughLinesP(th3, 1, np.pi / 180, 150, None, 0, 0)\n",
    "for line in lines:\n",
    "\t    x1, y1, x2, y2 = line[0]\n",
    "\t    cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "#cv2.namedWindow('Result Image', cv2.WINDOW_NORMAL)\n",
    "cv2.namedWindow('Result Image', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Result Image\", frame)\n",
    "while cv2.waitKey(0) != ord('q'):\n",
    "        pass\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eof\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(fname)\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#outv = cv2.VideoWriter('output.avi', cv2.CAP_GSTREAMER, 20.0, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"eof\")\n",
    "        break\n",
    "\n",
    "    src = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #dst = cv2.Canny(src, 50, 100, None, 3)\n",
    "    blur = cv2.GaussianBlur(src,(5,5),0)\n",
    "    ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    cnts = cv2.findContours(th3, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    cnts = grab_contours(cnts) \n",
    "\n",
    "    # Find the contour with the maximum area.\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    # Get bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "    # Crop the bounding rectangle out of img\n",
    "    out = frame[y:y+h, x:x+w, :].copy()\n",
    "    #outv.write(out.astype('uint8'))\n",
    "\n",
    "    #lines = cv2.HoughLinesP(th3, 1, np.pi / 180, 150, None, 0, 0)\n",
    "    #for line in lines:\n",
    "    #        x1, y1, x2, y2 = line[0]\n",
    "    #        cv2.line(frame, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
    "\n",
    "    cv2.namedWindow('Result Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Result Image\", out)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "#outv.release(\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"./judd.webm\"\n",
    "cap = cv2.VideoCapture(fname)\n",
    "\n",
    "shot = []\n",
    "\n",
    "# TODO: Automatic table corner detection\n",
    "ret, frame = cap.read()\n",
    "#cv2.imshow(\"Image\", frame)\n",
    "pts_src = get_four_points(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eof\n"
     ]
    }
   ],
   "source": [
    "size = (500, 1000, 3)\n",
    "pts_dst = np.array(\n",
    "               [\n",
    "                [0,0],\n",
    "                [size[0] - 1, 0],\n",
    "                [size[0] - 1, size[1] -1],\n",
    "                [0, size[1] - 1 ]\n",
    "                ], dtype=float\n",
    "               )\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"eof\")\n",
    "        break\n",
    "\n",
    "    h, status = cv2.findHomography(pts_src, pts_dst)\n",
    "    im_dst = cv2.warpPerspective(frame, h, size[:2])\n",
    "    cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"Image\", im_dst)\n",
    "    shot.append(im_dst)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test.jpg\", shot[0])\n",
    "\n",
    "for frame in shot:\n",
    "    # Smooth\n",
    "    frame_blur = cv2.GaussianBlur(frame, (0,0), 2)\n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Snooker green color range for judd.webm\n",
    "    lowerb = np.array([52, 150, 50])\n",
    "    upperb = np.array([60, 255, 220])\n",
    "    mask = cv2.inRange(frame_hsv, lowerb, upperb)\n",
    "\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask_closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel) # Cleans inner points\n",
    "    \n",
    "    # Applies the mask to the original frame\n",
    "    _,mask_inv = cv2.threshold(mask_closing,5,255,cv2.THRESH_BINARY_INV)\n",
    "    masked_img = cv2.bitwise_and(frame,frame, mask=mask_inv)\n",
    "\n",
    "    ctrs, hierarchy = cv2.findContours(mask_inv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    ctrs = [ctr for ctr in ctrs\n",
    "                        if 300 < cv2.contourArea(ctr) < 1000\n",
    "                        #and cv2.minAreaRect(ctr)[1][0]*0.28 < cv2.minAreaRect(ctr)[1][1]\n",
    "                        #and cv2.minAreaRect(ctr)[1][1]*0.28 < cv2.minAreaRect(ctr)[1][0]\n",
    "            ]\n",
    "    frame = frame.copy()\n",
    "    #draw_rectangles(ctrs, frame)\n",
    "    cv2.drawContours(frame, ctrs, -1, (255, 0, 0), 3)\n",
    "    cv2.namedWindow('FRAME', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(\"FRAME\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = cv2.selectROI(\"tracker\", shot[0])\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) /build/opencv/src/opencv-4.5.3/modules/video/src/tracking/detail/tracking_feature.cpp:128: error: (-215:Assertion failed) !patchSize.empty() in function 'generateRandomFeature'\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-3af323558471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerMIL_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.3) /build/opencv/src/opencv-4.5.3/modules/video/src/tracking/detail/tracking_feature.cpp:128: error: (-215:Assertion failed) !patchSize.empty() in function 'generateRandomFeature'\n"
     ]
    }
   ],
   "source": [
    "tracker = cv2.TrackerMIL_create()\n",
    "tracker.init(shot[0], roi)\n",
    "for frame in shot:\n",
    "    frame = frame.copy()\n",
    "    _, roi = tracker.update(frame)\n",
    "    cv2.rectangle(frame, roi, (255, 0, 0), 2, 1)\n",
    "    cv2.imshow(\"tracker\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = cv2.TrackerCSRT(shot[0], roi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'MultiTracker'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-642c9112b640>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrackers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'MultiTracker'"
     ]
    }
   ],
   "source": [
    "trackers = cv2.legacy.MultiTracker_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}